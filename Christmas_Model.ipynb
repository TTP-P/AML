{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbe1e597",
   "metadata": {},
   "source": [
    "# ----Lightgbm-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7fe26a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LIGHTGBM_SUPPRESS_WARNINGS'] = '1'\n",
    "os.environ['PYTHONWARNINGS'] = 'ignore'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5152c32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: Performing GPU Pre-flight Check...\n",
      " GPU Pre-flight Check PASSED. LightGBM can access the GPU.\n",
      "\n",
      "\n",
      "RUNNING REGRESSION MODELS IN OOT VALIDATION MODE ===\n",
      "Loaded input file: Spotify_Model_Ready_Features_V2.csv (467061 rows)\n",
      "Added 'is_christmas' feature to dataset\n",
      "  Train: <= 2021-12-31 (364377 rows)\n",
      "  Val:   2021-12-31 < Date <= 2022-12-31 (72988 rows)\n",
      "  Test:  > 2022-12-31 (29696 rows)\n",
      "Cached 2 train subsets and 2 val subsets\n",
      "\n",
      "\n",
      "===== Processing Regression Target: Points_next_week =====\n",
      "Feature Set: baseline\n",
      "\n",
      "--- Hyperparameter Search for baseline ---\n",
      "\n",
      "Starting Hyperparameter Search (Mode: Regression)\n",
      "\n",
      "Fitting RandomizedSearchCV with early stopping...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's l1: 7.76183\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's l1: 7.80078\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l1: 7.69937\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's l1: 7.63805\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's l1: 7.61607\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's l1: 7.57933\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's l1: 7.66997\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's l1: 7.63892\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's l1: 7.60955\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's l1: 7.852\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's l1: 7.58637\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 7.88984\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's l1: 7.71347\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 7.65342\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's l1: 7.75927\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's l1: 7.61211\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's l1: 7.76048\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's l1: 7.8185\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's l1: 7.6869\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's l1: 7.58286\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's l1: 7.66812\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's l1: 7.62733\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's l1: 7.62706\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's l1: 7.70033\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's l1: 7.58848\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[296]\tvalid_0's l1: 7.59816\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l1: 7.85259\n",
      "Early stopping, best iteration is:\n",
      "[232]\tvalid_0's l1: 7.64712\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[192]\tvalid_0's l1: 7.80682\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's l1: 7.68873\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[287]\tvalid_0's l1: 7.58284\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 7.75693\n",
      "Early stopping, best iteration is:\n",
      "[217]\tvalid_0's l1: 7.65096\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's l1: 7.6032\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l1: 7.84836\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's l1: 7.61731\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l1: 7.68881\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's l1: 7.60029\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l1: 7.73872\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's l1: 7.57336\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l1: 7.62473\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l1: 7.66071\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's l1: 7.62403\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 7.59756\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's l1: 7.58566\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's l1: 7.81076\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's l1: 7.69553\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's l1: 7.77292\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 7.82693\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's l1: 7.63734\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l1: 7.67726\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's l1: 7.60039\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's l1: 7.57796\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's l1: 7.71701\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's l1: 7.8058\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's l1: 7.63821\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's l1: 7.77461\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's l1: 7.60475\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's l1: 7.58082\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's l1: 7.68689\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l1: 7.67524\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's l1: 7.66365\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's l1: 7.62648\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's l1: 7.63184\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's l1: 7.615\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's l1: 7.60649\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's l1: 7.58934\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's l1: 7.58327\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's l1: 7.57835\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's l1: 7.56501\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's l1: 7.85869\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's l1: 7.80392\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's l1: 7.71583\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's l1: 7.68192\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's l1: 7.87046\n",
      "Early stopping, best iteration is:\n",
      "[131]\tvalid_0's l1: 7.66127\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's l1: 7.63554\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's l1: 7.61793\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 7.72552\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's l1: 7.59653\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's l1: 7.65772\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's l1: 7.59487\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's l1: 7.85154\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's l1: 7.56951\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l1: 7.80591\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 7.69126\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l1: 7.6302\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 7.61504\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's l1: 7.58759\n",
      "Early stopping, best iteration is:\n",
      "[206]\tvalid_0's l1: 7.70984\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 7.60079\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's l1: 7.57496\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's l1: 7.65639\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l1: 7.81016\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's l1: 7.77392\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l1: 7.69957\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's l1: 7.79705\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[235]\tvalid_0's l1: 7.61388\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's l1: 7.67589\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's l1: 7.79675\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's l1: 7.6872\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 7.63315\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's l1: 7.64569\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[288]\tvalid_0's l1: 7.63631\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's l1: 7.57668\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[283]\tvalid_0's l1: 7.60962\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 7.70171\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l1: 7.60728\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's l1: 7.659\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's l1: 7.62047\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[288]\tvalid_0's l1: 7.58741\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 7.57738\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l1: 7.6226\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's l1: 7.59861\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l1: 7.60839\n",
      "Early stopping, best iteration is:\n",
      "[103]\tvalid_0's l1: 7.80468\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's l1: 7.6754\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's l1: 7.62587\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's l1: 7.59579\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 7.57083\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's l1: 7.84598\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's l1: 7.71344\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's l1: 7.64232\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's l1: 7.59844\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's l1: 7.55942\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's l1: 7.55835\n",
      "\n",
      "Best parameters found:\n",
      "{'subsample': 1.0, 'reg_lambda': 5, 'random_state': 42, 'num_leaves': 64, 'n_estimators': 300, 'max_depth': 8, 'learning_rate': 0.03, 'colsample_bytree': 0.9}\n",
      "\n",
      "Step 5: Training model for Points_next_week (baseline)\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's l1: 7.55784\tvalid_0's l2: 156.824\n",
      " Training duration logged to 'results/regression/Christmas_Model/Points_next_week/baseline/runtime_log_next_week.csv' (2.4 sec)\n",
      "Training complete. Best iteration: 269 | Device used: unknown\n",
      "Final model training complete. Best iteration: 269\n",
      "Final model saved to 'results/regression/Christmas_Model/Points_next_week/baseline/model_next_week.pkl'\n",
      "\n",
      "Step 7: Performing Out-of-Time (OOT) Hold-Out Testing\n",
      "\n",
      "--- Deriving and Evaluating Ranks from Points Predictions ---\n",
      "\n",
      "--- Derived Rank Evaluation (Aligned with Points Metrics) ---\n",
      "MAE (Rank): 7.808\n",
      "RMSE (Rank): 12.650\n",
      "R² (Rank): 0.952\n",
      "Spearman (Rank): 0.976\n",
      "\n",
      "--- OOT Hold-Out Results ---\n",
      "MAE: 7.66 ± 0.06\n",
      "RMSE: 12.30 ± 0.27\n",
      "R²: 0.95 ± 0.00\n",
      "Spearman Corr: 0.98 ± 0.00\n",
      "\n",
      "=== OOT Hold-Out Summary (Mean ± Std) ===\n",
      "+----+----------+--------+-------+\n",
      "|    | Metric   |   Mean |   Std |\n",
      "|----+----------+--------+-------|\n",
      "|  0 | MAE      |  7.657 | 0.057 |\n",
      "|  1 | RMSE     | 12.304 | 0.271 |\n",
      "|  2 | R2       |  0.954 | 0.002 |\n",
      "|  3 | Spearman |  0.977 | 0.001 |\n",
      "+----+----------+--------+-------+\n",
      "\n",
      "Evaluation summary saved to:\n",
      "  - Metrics CSV:      results/regression/Christmas_Model/Points_next_week/baseline/metrics_next_week_oot.csv\n",
      "  - Rank metrics CSV: results/regression/Christmas_Model/Points_next_week/baseline/metrics_derived_rank_oot.csv\n",
      "  - Importance CSV:   results/regression/Christmas_Model/Points_next_week/baseline/importance_next_week.csv\n",
      "  - Detailed preds:   results/regression/Christmas_Model/Points_next_week/baseline/oot_predictions_detailed_next_week.csv\n",
      "Residuals saved to 'results/regression/Christmas_Model/Points_next_week/baseline/residuals_next_week.csv'\n",
      " Prediction confidence interval saved to 'results/regression/Christmas_Model/Points_next_week/baseline/confidence_interval_next_week.csv' (σ=12.304)\n",
      "Feature importance saved to 'results/regression/Christmas_Model/Points_next_week/baseline/importance_next_week.csv'\n",
      "\n",
      "=== Computing Permutation Feature Importance (Model-Agnostic) ===\n",
      "Permutation importance saved to 'results/regression/Christmas_Model/Points_next_week/baseline/importance_permutation_next_week.csv'\n",
      "Detailed predictions for significance testing saved to 'results/regression/Christmas_Model/Points_next_week/baseline/oot_predictions_detailed_next_week.csv'\n",
      " All results and data for Points_next_week (baseline) saved to 'results/regression/Christmas_Model/Points_next_week/baseline'\n",
      "Feature Set: baseline_plus_christmas\n",
      "\n",
      "--- Hyperparameter Search for baseline_plus_christmas ---\n",
      "\n",
      "Starting Hyperparameter Search (Mode: Regression)\n",
      "\n",
      "Fitting RandomizedSearchCV with early stopping...\n",
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[52]\tvalid_0's l1: 7.78297\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's l1: 7.73373\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[63]\tvalid_0's l1: 7.679\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 7.6149\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's l1: 7.58334\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's l1: 7.55955\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's l1: 7.65354\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l1: 7.62287\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's l1: 7.83866\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's l1: 7.60073\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's l1: 7.56849\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l1: 7.89831\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's l1: 7.69461\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's l1: 7.63274\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's l1: 7.76535\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's l1: 7.73682\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's l1: 7.58816\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's l1: 7.80677\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's l1: 7.6624\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's l1: 7.66567\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's l1: 7.54832\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's l1: 7.61141\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's l1: 7.6011\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[215]\tvalid_0's l1: 7.68651\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 7.55322\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[264]\tvalid_0's l1: 7.59612\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's l1: 7.84135\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's l1: 7.78428\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[289]\tvalid_0's l1: 7.56635\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's l1: 7.67403\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's l1: 7.62267\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's l1: 7.63837\n",
      "Early stopping, best iteration is:\n",
      "[81]\tvalid_0's l1: 7.73032\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l1: 7.81125\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 7.57931\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's l1: 7.59848\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's l1: 7.70171\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's l1: 7.66218\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's l1: 7.54248\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's l1: 7.56384\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's l1: 7.63647\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's l1: 7.59866\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's l1: 7.55978\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 7.58168\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 7.54497\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's l1: 7.79075\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's l1: 7.67702\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's l1: 7.8172\n",
      "Early stopping, best iteration is:\n",
      "[114]\tvalid_0's l1: 7.76794\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's l1: 7.61893\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's l1: 7.66685\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's l1: 7.575\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l1: 7.79236\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's l1: 7.5349\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's l1: 7.6949\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 7.61498\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's l1: 7.76371\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's l1: 7.59365\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's l1: 7.55809\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's l1: 7.67074\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[226]\tvalid_0's l1: 7.64072\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[149]\tvalid_0's l1: 7.65875\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 7.605\n",
      "Early stopping, best iteration is:\n",
      "[193]\tvalid_0's l1: 7.61019\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's l1: 7.5898\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's l1: 7.59465\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's l1: 7.55508\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[247]\tvalid_0's l1: 7.56968\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[271]\tvalid_0's l1: 7.54196\n",
      "Early stopping, best iteration is:\n",
      "[252]\tvalid_0's l1: 7.54792\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's l1: 7.79884\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's l1: 7.8386\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's l1: 7.6999\n",
      "Early stopping, best iteration is:\n",
      "[219]\tvalid_0's l1: 7.66674\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's l1: 7.81733\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's l1: 7.64859\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's l1: 7.61219\n",
      "Early stopping, best iteration is:\n",
      "[68]\tvalid_0's l1: 7.71221\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's l1: 7.57339\n",
      "Early stopping, best iteration is:\n",
      "[66]\tvalid_0's l1: 7.64236\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l1: 7.59649\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's l1: 7.79908\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's l1: 7.54439\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's l1: 7.85357\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's l1: 7.5639\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's l1: 7.67788\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 7.59383\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's l1: 7.61563\n",
      "Early stopping, best iteration is:\n",
      "[71]\tvalid_0's l1: 7.55258\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's l1: 7.695\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's l1: 7.58044\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[220]\tvalid_0's l1: 7.63925\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 7.54452\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's l1: 7.79461\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's l1: 7.80027\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[244]\tvalid_0's l1: 7.58663\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's l1: 7.78231\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's l1: 7.68176\n",
      "Early stopping, best iteration is:\n",
      "[79]\tvalid_0's l1: 7.67457\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's l1: 7.66601\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's l1: 7.76087\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[248]\tvalid_0's l1: 7.55156\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[276]\tvalid_0's l1: 7.62685\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's l1: 7.59983\n",
      "Early stopping, best iteration is:\n",
      "[135]\tvalid_0's l1: 7.63497\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's l1: 7.67288\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[299]\tvalid_0's l1: 7.59731\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 7.63033\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's l1: 7.57412\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's l1: 7.54144\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's l1: 7.57253\n",
      "Early stopping, best iteration is:\n",
      "[153]\tvalid_0's l1: 7.60256\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l1: 7.61619\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's l1: 7.581\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's l1: 7.57072\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's l1: 7.81719\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's l1: 7.67428\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's l1: 7.61207\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's l1: 7.57769\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's l1: 7.53991\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's l1: 7.81614\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's l1: 7.68993\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's l1: 7.62405\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's l1: 7.57651\n",
      "Early stopping, best iteration is:\n",
      "[151]\tvalid_0's l1: 7.53025\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's l1: 7.50425\n",
      "\n",
      "Best parameters found:\n",
      "{'subsample': 1.0, 'reg_lambda': 7, 'random_state': 42, 'num_leaves': 128, 'n_estimators': 300, 'max_depth': 12, 'learning_rate': 0.05, 'colsample_bytree': 0.8}\n",
      "\n",
      "Step 5: Training model for Points_next_week (baseline_plus_christmas)\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's l1: 7.5065\tvalid_0's l2: 153.777\n",
      " Training duration logged to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/runtime_log_next_week.csv' (2.1 sec)\n",
      "Training complete. Best iteration: 144 | Device used: unknown\n",
      "Final model training complete. Best iteration: 144\n",
      "Final model saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/model_next_week.pkl'\n",
      "\n",
      "Step 7: Performing Out-of-Time (OOT) Hold-Out Testing\n",
      "\n",
      "--- Deriving and Evaluating Ranks from Points Predictions ---\n",
      "\n",
      "--- Derived Rank Evaluation (Aligned with Points Metrics) ---\n",
      "MAE (Rank): 7.790\n",
      "RMSE (Rank): 12.641\n",
      "R² (Rank): 0.952\n",
      "Spearman (Rank): 0.976\n",
      "\n",
      "--- OOT Hold-Out Results ---\n",
      "MAE: 7.65 ± 0.08\n",
      "RMSE: 12.31 ± 0.30\n",
      "R²: 0.95 ± 0.00\n",
      "Spearman Corr: 0.98 ± 0.00\n",
      "\n",
      "=== OOT Hold-Out Summary (Mean ± Std) ===\n",
      "+----+----------+--------+-------+\n",
      "|    | Metric   |   Mean |   Std |\n",
      "|----+----------+--------+-------|\n",
      "|  0 | MAE      |  7.651 | 0.078 |\n",
      "|  1 | RMSE     | 12.313 | 0.303 |\n",
      "|  2 | R2       |  0.954 | 0.002 |\n",
      "|  3 | Spearman |  0.977 | 0.001 |\n",
      "+----+----------+--------+-------+\n",
      "\n",
      "Evaluation summary saved to:\n",
      "  - Metrics CSV:      results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/metrics_next_week_oot.csv\n",
      "  - Rank metrics CSV: results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/metrics_derived_rank_oot.csv\n",
      "  - Importance CSV:   results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/importance_next_week.csv\n",
      "  - Detailed preds:   results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/oot_predictions_detailed_next_week.csv\n",
      "Residuals saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/residuals_next_week.csv'\n",
      " Prediction confidence interval saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/confidence_interval_next_week.csv' (σ=12.312)\n",
      "Feature importance saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/importance_next_week.csv'\n",
      "\n",
      "=== Computing Permutation Feature Importance (Model-Agnostic) ===\n",
      "Permutation importance saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/importance_permutation_next_week.csv'\n",
      "Detailed predictions for significance testing saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas/oot_predictions_detailed_next_week.csv'\n",
      " All results and data for Points_next_week (baseline_plus_christmas) saved to 'results/regression/Christmas_Model/Points_next_week/baseline_plus_christmas'\n",
      "\n",
      "Comparison between baseline and baseline_plus_christmas available for:\n",
      "  - Points_next_week\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.stats import spearmanr\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "from lightgbm import early_stopping, log_evaluation\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "from sklearn.inspection import permutation_importance\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "input_filename = 'Spotify_Model_Ready_Features_V2.csv'\n",
    "use_gpu = True \n",
    "\n",
    "# split dates\n",
    "TRAIN_END = pd.Timestamp('2021-12-31')\n",
    "VAL_END = pd.Timestamp('2022-12-31')\n",
    "\n",
    "BASELINE_FEATURES = [\n",
    "    'Danceability', 'Energy', 'Loudness_Corrected', 'Speechiness',\n",
    "    'Acousticness', 'Instrumentalness', 'Valence', 'Artist_Count',\n",
    "    'Nationality_Count', 'Rank', 'Points (Total)', 'Rank_last_week',\n",
    "    'Points_last_week', 'Rank_change', 'Points_change',\n",
    "    'Points_rolling_mean_4w', 'Rank_rolling_mean_4w',\n",
    "    'Weeks_on_chart', 'Artist_Hotness'\n",
    "]\n",
    "CHRISTMAS_FEATURES = BASELINE_FEATURES + ['is_christmas']\n",
    "\n",
    "\n",
    "def mark_christmas_period(date_series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Mark December and first week of January as Christmas period.\"\"\"\n",
    "    december = date_series.dt.month == 12\n",
    "    january_first_week = (date_series.dt.month == 1) & (date_series.dt.day <= 7)\n",
    "    return (december | january_first_week).astype(int)\n",
    "\n",
    "\n",
    "def train_regression_pipeline(\n",
    "    df_train, df_val, df_oot, feature_columns, target_column, model_params,\n",
    "    model_name=\"\", save_detailed_predictions=False\n",
    "):\n",
    "\n",
    "    try:\n",
    "        output_dir = os.path.join(\"results\", \"regression\", \"Christmas_Model\", target_column, model_name)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        suffix = target_column.replace('Points_', '')\n",
    "        \n",
    "        metrics_output_filename = os.path.join(output_dir, f\"metrics_{suffix}_oot.csv\")\n",
    "        importance_output_filename = os.path.join(output_dir, f\"importance_{suffix}.csv\")\n",
    "        model_output_filename = os.path.join(output_dir, f\"model_{suffix}.pkl\")\n",
    "        oot_predictions_output_filename = os.path.join(output_dir, f\"oot_predictions_and_actuals.csv\")\n",
    "        rank_metrics_filename = os.path.join(output_dir, f\"metrics_derived_rank_oot.csv\")\n",
    "        \n",
    "\n",
    "        print(f\"\\nStep 5: Training model for {target_column} ({model_name})\")\n",
    "    \n",
    "        # Prepare training data\n",
    "        df_train_target = df_train.dropna(subset=[target_column]).copy()\n",
    "        X_train = df_train_target[feature_columns]\n",
    "        y_train = df_train_target[target_column]\n",
    "        \n",
    "        if X_train.empty:\n",
    "            print(f\"Skipping {target_column}: No training data available after dropna.\")\n",
    "            return\n",
    "        \n",
    "        # Prepare validation data\n",
    "        df_val_target = df_val.dropna(subset=[target_column]).copy()\n",
    "        X_val = df_val_target[feature_columns]\n",
    "        y_val = df_val_target[target_column]\n",
    "        \n",
    "        if X_val.empty:\n",
    "            print(f\"Warning: Validation set for {target_column} is empty.\")\n",
    "            return\n",
    "        \n",
    "        # Train model with validation set for early stopping\n",
    "        start_time = time.time()\n",
    "        final_model = lgb.LGBMRegressor(**model_params)\n",
    "        \n",
    "        # Reuse static callbacks to reduce overhead\n",
    "        if not hasattr(train_regression_pipeline, \"_callbacks\"):\n",
    "            train_regression_pipeline._callbacks = [\n",
    "                early_stopping(stopping_rounds=30),\n",
    "                log_evaluation(period=0)\n",
    "            ]\n",
    "        callbacks = train_regression_pipeline._callbacks\n",
    "        \n",
    "        final_model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric=\"mae\",\n",
    "            callbacks=callbacks,\n",
    "        )\n",
    "        end_time = time.time()\n",
    "        train_duration = end_time - start_time\n",
    "        runtime_log_path = os.path.join(output_dir, f\"runtime_log_{suffix}.csv\")\n",
    "        pd.DataFrame({\n",
    "            'model': [model_name],\n",
    "            'target': [target_column],\n",
    "            'train_time_sec': [train_duration]\n",
    "        }).to_csv(runtime_log_path, sep=';', index=False)\n",
    "        print(f\" Training duration logged to '{runtime_log_path}' ({train_duration:.1f} sec)\")\n",
    "        \n",
    "        train_curve = final_model.evals_result_\n",
    "        if train_curve and 'training' in train_curve and 'l1' in train_curve['training']:\n",
    "            curve_df = pd.DataFrame({\n",
    "                'iteration': range(len(train_curve['training']['l1'])),\n",
    "                'train_mae': train_curve['training']['l1'],\n",
    "                'val_mae': train_curve['valid_0']['l1']\n",
    "            })\n",
    "            curve_path = os.path.join(output_dir, f\"training_curve_{suffix}.csv\")\n",
    "            curve_df.to_csv(curve_path, sep=';', index=False)\n",
    "            print(f\"Training curve saved to '{curve_path}'\")\n",
    "        \n",
    "        try:\n",
    "            device_type = final_model.booster_.params.get(\"device_type\", \"unknown\")\n",
    "            print(f\"Training complete. Best iteration: {final_model.best_iteration_} | Device used: {device_type}\")\n",
    "        except Exception as e:\n",
    "            print(\"Unable to detect device type:\", e)\n",
    "\n",
    "        print(f\"Final model training complete. Best iteration: {final_model.best_iteration_}\")\n",
    "\n",
    "        joblib.dump(final_model, model_output_filename)\n",
    "        print(f\"Final model saved to '{model_output_filename}'\")\n",
    "        \n",
    "        print(\"\\nStep 7: Performing Out-of-Time (OOT) Hold-Out Testing\")\n",
    "\n",
    "        df_oot_target = df_oot.dropna(subset=[target_column]).copy()\n",
    "        X_oot = df_oot_target[feature_columns]\n",
    "        y_oot = df_oot_target[target_column]\n",
    "\n",
    "        if X_oot.empty:\n",
    "            print(f\"Warning: OOT set for {target_column} is empty. Skipping OOT evaluation.\")\n",
    "            return\n",
    "\n",
    "        oot_predictions = final_model.predict(X_oot)\n",
    "\n",
    "\n",
    "        print(\"\\n--- Deriving and Evaluating Ranks from Points Predictions ---\")\n",
    "\n",
    "\n",
    "        results_df = df_oot_target[['Date']].copy()\n",
    "        results_df['true_points'] = y_oot\n",
    "        results_df['predicted_points'] = oot_predictions\n",
    "\n",
    "\n",
    "        true_rank_col_name = target_column.replace('Points', 'Rank')\n",
    "        results_df['true_rank'] = df_oot_target[true_rank_col_name]\n",
    "\n",
    "        results_df['predicted_rank'] = results_df.groupby('Date')['predicted_points'].rank(\n",
    "            method='first', ascending=False\n",
    "        )\n",
    "\n",
    "\n",
    "        mae_rank = mean_absolute_error(results_df['true_rank'], results_df['predicted_rank'])\n",
    "        rmse_rank = np.sqrt(mean_squared_error(results_df['true_rank'], results_df['predicted_rank']))\n",
    "        r2_rank = r2_score(results_df['true_rank'], results_df['predicted_rank'])\n",
    "        spearman_rank, _ = spearmanr(results_df['true_rank'], results_df['predicted_rank'])\n",
    "\n",
    "        print(\"\\n--- Derived Rank Evaluation (Aligned with Points Metrics) ---\")\n",
    "        print(f\"MAE (Rank): {mae_rank:.3f}\")\n",
    "        print(f\"RMSE (Rank): {rmse_rank:.3f}\")\n",
    "        print(f\"R² (Rank): {r2_rank:.3f}\")\n",
    "        print(f\"Spearman (Rank): {spearman_rank:.3f}\")\n",
    "\n",
    "\n",
    "        mae_oot = mean_absolute_error(y_oot, oot_predictions)\n",
    "        r2_oot = r2_score(y_oot, oot_predictions)\n",
    "        spearman_oot, _ = spearmanr(y_oot, oot_predictions)\n",
    "        rmse_oot = np.sqrt(mean_squared_error(y_oot, oot_predictions))\n",
    "        \n",
    "        def compute_metric_std(y_true, y_pred, n_splits=3):\n",
    "            size = len(y_true) // n_splits\n",
    "            maes, r2s, rmses, spearmans = [], [], [], []\n",
    "            for i in range(n_splits):\n",
    "                start, end = i * size, (i + 1) * size\n",
    "                y_t, y_p = y_true[start:end], y_pred[start:end]\n",
    "                if len(y_t) == 0: continue\n",
    "                maes.append(mean_absolute_error(y_t, y_p))\n",
    "                r2s.append(r2_score(y_t, y_p))\n",
    "                rmses.append(np.sqrt(mean_squared_error(y_t, y_p)))\n",
    "\n",
    "                if len(np.unique(y_t)) > 1 and len(np.unique(y_p)) > 1:\n",
    "                    spearmans.append(spearmanr(y_t, y_p)[0])\n",
    "                else:\n",
    "                    spearmans.append(np.nan)\n",
    "            \n",
    "            return {\n",
    "                'MAE_std': np.nanstd(maes),\n",
    "                'R2_std': np.nanstd(r2s),\n",
    "                'RMSE_std': np.nanstd(rmses),\n",
    "                'Spearman_std': np.nanstd(spearmans)\n",
    "            }\n",
    "        \n",
    "        metric_std = compute_metric_std(y_oot.values, oot_predictions, n_splits=3)\n",
    "\n",
    "        print(\"\\n--- OOT Hold-Out Results ---\")\n",
    "        print(f\"MAE: {mae_oot:.2f} ± {metric_std['MAE_std']:.2f}\")\n",
    "        print(f\"RMSE: {rmse_oot:.2f} ± {metric_std['RMSE_std']:.2f}\")\n",
    "        print(f\"R²: {r2_oot:.2f} ± {metric_std['R2_std']:.2f}\")\n",
    "        print(f\"Spearman Corr: {spearman_oot:.2f} ± {metric_std['Spearman_std']:.2f}\")\n",
    "\n",
    "        oot_results_df = pd.DataFrame({\n",
    "            'Metric': ['MAE', 'RMSE', 'R2', 'Spearman'],\n",
    "            'Mean': [mae_oot, rmse_oot, r2_oot, spearman_oot],\n",
    "            'Std': [\n",
    "                metric_std['MAE_std'],\n",
    "                metric_std['RMSE_std'],\n",
    "                metric_std['R2_std'],\n",
    "                metric_std['Spearman_std']\n",
    "            ]\n",
    "        })\n",
    "        oot_results_df.to_csv(metrics_output_filename, index=False, sep=';')\n",
    "\n",
    "\n",
    "        print(\"\\n=== OOT Hold-Out Summary (Mean ± Std) ===\")\n",
    "        print(tabulate(\n",
    "            oot_results_df,\n",
    "            headers=\"keys\",\n",
    "            tablefmt=\"psql\", \n",
    "            floatfmt=\".3f\"\n",
    "        ))\n",
    "\n",
    "        print(f\"\\nEvaluation summary saved to:\")\n",
    "        print(f\"  - Metrics CSV:      {metrics_output_filename}\")\n",
    "        print(f\"  - Rank metrics CSV: {rank_metrics_filename}\")\n",
    "        print(f\"  - Importance CSV:   {importance_output_filename}\")\n",
    "        if save_detailed_predictions:\n",
    "            detailed_output_filename = os.path.join(output_dir, f\"oot_predictions_detailed_{suffix}.csv\")\n",
    "            print(f\"  - Detailed preds:   {detailed_output_filename}\")\n",
    "\n",
    "\n",
    "\n",
    "        oot_output_df = pd.DataFrame({'y_true': y_oot, 'y_pred': oot_predictions})\n",
    "        oot_output_df.to_csv(oot_predictions_output_filename, index=False, sep=';')\n",
    "\n",
    "        residuals = y_oot - oot_predictions\n",
    "        residuals_df = pd.DataFrame({\n",
    "            'Date': df_oot_target['Date'],\n",
    "            'y_true': y_oot,\n",
    "            'y_pred': oot_predictions,\n",
    "            'residual': residuals\n",
    "        })\n",
    "        residuals_path = os.path.join(output_dir, f\"residuals_{suffix}.csv\")\n",
    "        residuals_df.to_csv(residuals_path, sep=';', index=False)\n",
    "        print(f\"Residuals saved to '{residuals_path}'\")\n",
    "\n",
    "\n",
    "        residual_std = np.std(residuals)\n",
    "        ci_lower = oot_predictions - 1.96 * residual_std\n",
    "        ci_upper = oot_predictions + 1.96 * residual_std\n",
    "\n",
    "        ci_df = pd.DataFrame({\n",
    "            'y_pred': oot_predictions,\n",
    "            'ci_lower': ci_lower,\n",
    "            'ci_upper': ci_upper\n",
    "        })\n",
    "        ci_path = os.path.join(output_dir, f\"confidence_interval_{suffix}.csv\")\n",
    "        ci_df.to_csv(ci_path, sep=';', index=False)\n",
    "        print(f\" Prediction confidence interval saved to '{ci_path}' (σ={residual_std:.3f})\")\n",
    "\n",
    "\n",
    "\n",
    "        feature_importance_df = pd.DataFrame({\n",
    "            'feature': feature_columns,\n",
    "            'importance': final_model.feature_importances_\n",
    "        }).sort_values('importance', ascending=False).reset_index(drop=True)\n",
    "        feature_importance_df.to_csv(importance_output_filename, index=False, sep=';')\n",
    "\n",
    "        print(f\"Feature importance saved to '{importance_output_filename}'\")\n",
    "\n",
    "\n",
    "        try:\n",
    "            print(\"\\n=== Computing Permutation Feature Importance (Model-Agnostic) ===\")\n",
    "            perm_output_filename = os.path.join(output_dir, f\"importance_permutation_{suffix}.csv\")\n",
    "\n",
    "            perm_result = permutation_importance(\n",
    "                final_model, X_oot, y_oot,\n",
    "                scoring='neg_mean_absolute_error',\n",
    "                n_repeats=10,\n",
    "                random_state=42\n",
    "            )\n",
    "\n",
    "            perm_importance_df = pd.DataFrame({\n",
    "                'feature': feature_columns,\n",
    "                'importance_mean': perm_result.importances_mean,\n",
    "                'importance_std': perm_result.importances_std\n",
    "            }).sort_values('importance_mean', ascending=False)\n",
    "\n",
    "            perm_importance_df.to_csv(perm_output_filename, sep=';', index=False)\n",
    "            print(f\"Permutation importance saved to '{perm_output_filename}'\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Permutation importance computation failed: {e}\")\n",
    "\n",
    "        \n",
    "\n",
    "        if save_detailed_predictions:\n",
    "            detailed_preds_df = df_oot_target[['Date', target_column]].copy()\n",
    "            detailed_preds_df['y_pred'] = oot_predictions\n",
    "            detailed_preds_df['model_name'] = model_name\n",
    "            \n",
    "            detailed_output_filename = os.path.join(output_dir, f\"oot_predictions_detailed_{suffix}.csv\")\n",
    "            detailed_preds_df.to_csv(detailed_output_filename, index=False, sep=';')\n",
    "            print(f\"Detailed predictions for significance testing saved to '{detailed_output_filename}'\")\n",
    "\n",
    "\n",
    "        print(f\" All results and data for {target_column} ({model_name}) saved to '{output_dir}'\")\n",
    "\n",
    "        return pd.DataFrame({'y_true': y_oot, 'y_pred': oot_predictions})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during processing for {target_column} ({model_name}): {e}\")\n",
    "\n",
    "\n",
    "def hyperparameter_search(X_train, y_train):\n",
    "    print(f\"\\nStarting Hyperparameter Search (Mode: {'Regression'})\")\n",
    "    \n",
    "    param_dist = {\n",
    "        \"max_depth\": [6, 8, 10, 12],\n",
    "        \"num_leaves\": [32, 64, 128, 256],\n",
    "        \"learning_rate\": [0.03, 0.05, 0.08, 0.1],\n",
    "        \"n_estimators\": [300],\n",
    "        \"reg_lambda\": [3, 5, 7, 9],\n",
    "        \"subsample\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"colsample_bytree\": [0.7, 0.8, 0.9, 1.0],\n",
    "        \"random_state\": [42],\n",
    "    }\n",
    "    \n",
    "    N_ITER = 25\n",
    "    N_SPLITS = 5\n",
    "    total_fits = N_ITER * N_SPLITS\n",
    "    device = 'gpu' if use_gpu else 'cpu'\n",
    "    \n",
    "    base_estimator = lgb.LGBMRegressor(\n",
    "        objective='regression',\n",
    "        metric='mae',\n",
    "        random_state=42,\n",
    "        n_jobs=1,  \n",
    "        device=device,\n",
    "        verbose=-1,\n",
    "    )\n",
    "    \n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=base_estimator,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=N_ITER,\n",
    "        scoring='neg_mean_absolute_error',\n",
    "        cv=TimeSeriesSplit(n_splits=N_SPLITS),\n",
    "        n_jobs=-1,  \n",
    "        random_state=42,\n",
    "        verbose=1,  \n",
    "    )\n",
    "\n",
    "    print(\"\\nFitting RandomizedSearchCV with early stopping...\")\n",
    "    callbacks = [\n",
    "        early_stopping(stopping_rounds=30),\n",
    "        log_evaluation(period=0)\n",
    "    ]\n",
    "\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(random_search.best_params_)\n",
    "    return random_search.best_params_\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    os.environ[\"LIGHTGBM_USE_GPU\"] = \"1\"\n",
    "    os.environ[\"GPU_PLATFORM_ID\"] = \"0\"\n",
    "    os.environ[\"GPU_DEVICE_ID\"] = \"0\"\n",
    "    os.environ[\"LIGHTGBM_DEBUG_VERBOSE\"] = \"0\"\n",
    "\n",
    "    print(\"Step 0: Performing GPU Pre-flight Check...\")\n",
    "    dummy_X = np.random.rand(10, 5)\n",
    "    dummy_y = np.random.rand(10)\n",
    "    dummy_model = lgb.LGBMRegressor(device='gpu')\n",
    "    dummy_model.fit(dummy_X, dummy_y)\n",
    "    print(\" GPU Pre-flight Check PASSED. LightGBM can access the GPU.\")\n",
    "\n",
    "    print(\"\\n\\nRUNNING REGRESSION MODELS IN OOT VALIDATION MODE ===\")\n",
    "    df = pd.read_csv(input_filename, sep=';', parse_dates=['Date'])\n",
    "    df.sort_values('Date', inplace=True)\n",
    "    print(f\"Loaded input file: {input_filename} ({df.shape[0]} rows)\")\n",
    "\n",
    "    if 'is_christmas' not in df.columns:\n",
    "        df['is_christmas'] = mark_christmas_period(df['Date'])\n",
    "        print(\"Added 'is_christmas' feature to dataset\")\n",
    "    else:\n",
    "        df['is_christmas'] = df['is_christmas'].astype(int)\n",
    "        print(\"'is_christmas' feature already present in dataset\")\n",
    "    \n",
    "    \n",
    "    # split train / val / test\n",
    "    train_df = df[df['Date'] <= TRAIN_END].copy()\n",
    "    val_df = df[(df['Date'] > TRAIN_END) & (df['Date'] <= VAL_END)].copy()\n",
    "    test_df = df[df['Date'] > VAL_END].copy()\n",
    "\n",
    "    print(f\"  Train: <= {TRAIN_END.date()} ({train_df.shape[0]} rows)\")\n",
    "    print(f\"  Val:   {TRAIN_END.date()} < Date <= {VAL_END.date()} ({val_df.shape[0]} rows)\")\n",
    "    print(f\"  Test:  > {VAL_END.date()} ({test_df.shape[0]} rows)\")\n",
    "    \n",
    "    # feature sets for comparison\n",
    "    feature_sets = {\n",
    "        'baseline': BASELINE_FEATURES,\n",
    "        'baseline_plus_christmas': CHRISTMAS_FEATURES,\n",
    "    }\n",
    "    \n",
    "    regression_targets = ['Points_next_week']\n",
    "    \n",
    "    cached_train = {}\n",
    "    cached_val = {}\n",
    "    for target in regression_targets:\n",
    "        for feature_set_name, feature_cols in feature_sets.items():\n",
    "            train_subset = train_df.dropna(subset=[target])\n",
    "            if not train_subset.empty:\n",
    "                cache_key = f\"{target}_{feature_set_name}\"\n",
    "                cached_train[cache_key] = (train_subset[feature_cols], train_subset[target])\n",
    "            \n",
    "            val_subset = val_df.dropna(subset=[target])\n",
    "            if not val_subset.empty:\n",
    "                cache_key = f\"{target}_{feature_set_name}\"\n",
    "                cached_val[cache_key] = (val_subset[feature_cols], val_subset[target])\n",
    "    print(f\"Cached {len(cached_train)} train subsets and {len(cached_val)} val subsets\")\n",
    "\n",
    "    \n",
    "    for target in regression_targets:\n",
    "        print(f\"\\n\\n===== Processing Regression Target: {target} =====\")\n",
    "        \n",
    "        for feature_set_name, feature_cols in feature_sets.items():\n",
    "            cache_key = f\"{target}_{feature_set_name}\"\n",
    "        \n",
    "            if cache_key not in cached_train or cache_key not in cached_val:\n",
    "                print(f\"\\nSkipping {target} with {feature_set_name}: Missing train or val data\")\n",
    "                continue\n",
    "        \n",
    "            print(f\"Feature Set: {feature_set_name}\")\n",
    "\n",
    "            X_train, y_train = cached_train[cache_key]\n",
    "            X_val, y_val = cached_val[cache_key]\n",
    "            X_dev = pd.concat([X_train, X_val], axis=0, ignore_index=True)\n",
    "            y_dev = pd.concat([y_train, y_val], axis=0, ignore_index=True)\n",
    "\n",
    "            print(f\"\\n--- Hyperparameter Search for {feature_set_name} ---\")\n",
    "            best_params = hyperparameter_search(\n",
    "                X_train, y_train, \n",
    "                X_val, y_val)\n",
    "            \n",
    "            best_params['random_state'] = 42\n",
    "            best_params['device'] = 'gpu' if use_gpu else 'cpu'\n",
    "            best_params['bagging_seed'] = 42\n",
    "            best_params['feature_fraction_seed'] = 42\n",
    "            best_params['n_estimators'] = 1800\n",
    "            \n",
    "            train_regression_pipeline(\n",
    "                train_df,\n",
    "                val_df,\n",
    "                test_df,\n",
    "                feature_cols,\n",
    "                target,\n",
    "                best_params,\n",
    "                model_name=feature_set_name,\n",
    "                save_detailed_predictions=True,\n",
    "            )\n",
    "    \n",
    "\n",
    "    print(\"\\nComparison between baseline and baseline_plus_christmas available for:\")\n",
    "    for target in regression_targets:\n",
    "        print(f\"  - {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b2299e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
