epoch;train_loss;val_loss
1;654.9233742163908;445.7892859430596
2;371.75143438332935;425.5657181983128
3;349.6450949981878;412.0840028906631
4;339.4616749097539;406.807119710883
5;334.72278125181356;399.93068530336194
6;330.79227013015975;401.3147370192447
7;328.3750263383;397.2539139084478
8;326.71035966604336;404.84149720481764
9;324.7695522184024;393.4723109661489
10;323.75389990454994;395.8792064489523
11;321.9858515177634;391.34958940376697
12;321.00457433159505;391.1627129455241
13;319.6877265096387;395.637981821541
14;319.1111873664491;398.39590097036603
15;318.00083489459604;388.09157849302386
16;317.8746639691854;391.8473825854195
17;316.6424022003848;387.24872727405
18;315.9574790692376;396.96328901536396
19;315.4131567197842;388.2907237004253
20;315.06732305127764;393.2314997874229
21;314.8200373285097;390.0190246535546
22;314.14196652017074;388.0095124458958
23;313.7763233496436;385.89528368087736
24;313.13018540263147;390.8040751205177
25;312.89934416082866;394.4408689209821
26;312.34460650819994;389.130409014107
27;312.0414085895174;387.94715184068644
28;311.41019629140436;391.6597762009794
29;311.8384272338756;391.68449595640925
30;311.0830830805168;386.03407592657226
31;311.0664346498447;387.64557882746215
32;311.031070216447;387.1254517786937
33;310.5543082116228;390.30506716551713
